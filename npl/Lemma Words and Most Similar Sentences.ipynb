{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d7500a",
   "metadata": {},
   "source": [
    "# NATURAL PROCESS LANGUAGE (NPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4654380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9c4b5263",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'is'\n",
    "y = 'was'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d411a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet') #Download Dictionary\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5d2a923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6dd1099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmma x: be\n",
      "Lemmma y: be\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma1 = lemmatizer.lemmatize(x, 'v') # v for verb\n",
    "print(f'Lemmma x: {lemma1}')\n",
    "lemma2 = lemmatizer.lemmatize(y, 'v') # v for verb\n",
    "print(f'Lemmma y: {lemma2}')\n",
    "lemma1 == lemma2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432cedf9",
   "metadata": {},
   "source": [
    "## LEMMATIZATION OF SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "95e0d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e440df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Vegetables are types of plants.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c7123",
   "metadata": {},
   "source": [
    "_**Tokenizing Sentences**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "de3fb022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originally, vegetables were collected from the wild by hunter-gatherers.\n",
      "Vegetables are all plants.\n",
      "Vegetables can be eaten either raw or cooked\n",
      "What are vegetables?\n"
     ]
    }
   ],
   "source": [
    "for token in sentence_tokens:\n",
    "    lemma = lemmatizer.lemmatize(token, 'n') #n for noum\n",
    "    print(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "846915a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_me(sent):\n",
    "    sentence_tokens = nltk.word_tokenize(sent.lower())\n",
    "    pos_tags = nltk.pos_tag(sentence_tokens) #type of the words ( verb, noum, adverb, etc)\n",
    "\n",
    "    sentence_lemmas = []\n",
    "\n",
    "    for token, pos_tag in zip(sentence_tokens, pos_tags):\n",
    "        if pos_tag[1][0].lower() in ['n', 'v', 'a','r']:\n",
    "            lemma = lemmatizer.lemmatize(token, pos_tag[1][0].lower())\n",
    "            sentence_lemmas.append(lemma)\n",
    "            \n",
    "    return sentence_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bdb6ef8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vegetable', 'be', 'type', 'plant']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = lemma_me(sentence)\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "41ef513e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vegetable', 'be', 'type', 'plant']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = lemma_me('A vegetable is a type of plant')\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d771ab9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 == l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde8c5b",
   "metadata": {},
   "source": [
    "## Find the most similar sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "488857ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Originally, vegetables were collected from the wild by hunter-gatherers. Vegetables are all plants. Vegetables can be eaten either raw or cooked'\n",
    "question = 'What are vegetables?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "94ef075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity #find similarities\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ca84bd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Originally, vegetables were collected from the wild by hunter-gatherers.', 'Vegetables are all plants.', 'Vegetables can be eaten either raw or cooked', 'What are vegetables?']\n"
     ]
    }
   ],
   "source": [
    "sentence_tokens = nltk.sent_tokenize(text)\n",
    "sentence_tokens.append(question)\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "075a8ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(tokenizer=<function lemma_me at 0x0000027ABBE1D280>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer(tokenizer = lemma_me )\n",
    "tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "87c08834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x8 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tv.fit_transform(sentence_tokens)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c14b6250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27717414, 0.53114624, 0.        , 0.        , 0.53114624,\n",
       "        0.53114624, 0.        , 0.27717414],\n",
       "       [0.41988018, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.8046125 , 0.41988018],\n",
       "       [0.32713399, 0.        , 0.62688384, 0.62688384, 0.        ,\n",
       "        0.        , 0.        , 0.32713399],\n",
       "       [0.70710678, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.70710678]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bef65b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenny\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>collect</th>\n",
       "      <th>cook</th>\n",
       "      <th>eat</th>\n",
       "      <th>hunter-gatherer</th>\n",
       "      <th>originally</th>\n",
       "      <th>plant</th>\n",
       "      <th>vegetable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277174</td>\n",
       "      <td>0.531146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531146</td>\n",
       "      <td>0.531146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.419880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804612</td>\n",
       "      <td>0.419880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626884</td>\n",
       "      <td>0.626884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         be   collect      cook       eat  hunter-gatherer  originally  \\\n",
       "0  0.277174  0.531146  0.000000  0.000000         0.531146    0.531146   \n",
       "1  0.419880  0.000000  0.000000  0.000000         0.000000    0.000000   \n",
       "2  0.327134  0.000000  0.626884  0.626884         0.000000    0.000000   \n",
       "3  0.707107  0.000000  0.000000  0.000000         0.000000    0.000000   \n",
       "\n",
       "      plant  vegetable  \n",
       "0  0.000000   0.277174  \n",
       "1  0.804612   0.419880  \n",
       "2  0.000000   0.327134  \n",
       "3  0.000000   0.707107  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tf.toarray(), columns=tv.get_feature_names())\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "739a0779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39198343, 0.59380024, 0.46263733, 1.        ]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = cosine_similarity(tf[-1], tf ) #With two lists\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ee50e3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = values.argsort()[0][2] #High value excluding the proper question\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0b09da0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39198343, 0.46263733, 0.59380024, 1.        ])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_flat = values.flatten() #Just one list\n",
    "values_flat.sort()\n",
    "values_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "62134e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.593800244493221"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff = values_flat[-2]\n",
    "coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "76e58e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegetables are all plants.\n"
     ]
    }
   ],
   "source": [
    "if coeff > 0.3:\n",
    "    print(sentence_tokens[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a0944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
